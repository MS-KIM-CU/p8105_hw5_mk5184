---
title: "p8105_hw5_mk5184"
author: "Minseo Brenda Kim"
date: "2025-11-14"
output: github_document
---

```{r}
# load necessary libraries
library(tidyverse)
library(broom)
```

## Problem 1

Suppose you put $n$ people in a room, and want to know the probability that at least two people share a birthday. For simplicity, we’ll assume there are no leap years (i.e. there are only 365 days) and that birthdays are uniformly distributed over the year (which is actually not the case).

```{r}
# Function to check if at least two people share a birthday in a group of size n

fn_birthday <- function(n) {
  birthdays <- sample(1:365, n, replace = TRUE)  # Samples n birthdays from 1 to 365 (uniformly, with replacement), returns TRUE if there's a shared birthday, FALSE otherwise
  any(duplicated(birthdays)) # Uses any(duplicated()) to detect duplicates
}
```

```{r}
set.seed(123)

num_sims <- 10000  #run this function 10000 times for each group size 
group_sizes <- 2:50  #between 2 and 50

# compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs
prob <- map_dbl(group_sizes, ~ {
  results <- replicate(num_sims, fn_birthday(.x))
  mean(results)
})

birthday_df <- tibble(
  group_size = group_sizes,
  prob_shared = prob
)
```

```{r}
# Make a plot showing the probability as a function of group size
birthday_df |> 
  ggplot(aes(x = group_size, y = prob_shared)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthday vs. Group Size",
    x = "Group Size",
    y = "Probability of At Least One Shared Birthday"
  ) +
  theme_minimal()
```
The plot shows the probability of at least one shared birthday starts low for small groups but increases proportionately. It crosses 0.4 around n=23 and approaching 1 by n = 50.

## Problem 2

```{r}
# fix n = 30, σ = 5
# For each dataset, save μ̂ and the p-value arising from a test of H: μ = 0 using α = 0.05. Hint: to obtain the estimate and p-value, use broom::tidy to clean the output of t.test.

sim_t_test <- function(mu, n = 30, sigma = 5) {
  data <- rnorm(n, mean = mu, sd = sigma)
  t_test <- t.test(data, mu = 0)
  tidy(t_test) |> 
    select(estimate, p.value)
}
```

```{r}
set.seed(123)

# set μ = 0. Generate 5000 datasets from the model x ~ Normal[μ, σ]
num_sims <- 5000
true_mus <- 0:6 # Repeat the above for μ = {1,2,3,4,5,6}

# generate datasets and collect results
sim_results <- true_mus |> 
  map(~ {
    replicate(num_sims, sim_t_test(.x), simplify = FALSE) |> 
      bind_rows() |> 
      mutate(true_mu = .x)
  }) |> 
  bind_rows()
```

```{r}
summary_df <- sim_results |> 
  group_by(true_mu) |> 
  summarize(
    power = mean(p.value < 0.05),
    avg_estimate = mean(estimate),
    avg_estimate_rejected = mean(estimate[p.value < 0.05])
  )

summary_df
```

```{r}
# Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis.
summary_df |> 
  ggplot(aes(x = true_mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(title = "Power vs. True Mean", x = "True Mean (μ)", y = "Power") +
  theme_minimal()
```

```{r}
# Make a plot showing the average estimate of μ̂ on the y axis and the true value of μ on the x axis.
# Make a second plot (or overlay on the first) the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.
summary_df |> 
  pivot_longer(cols = c(avg_estimate, avg_estimate_rejected),
               names_to = "type", values_to = "value") |> 
  ggplot(aes(x = true_mu, y = value, color = type)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Average Estimate vs. True Mean",
    x = "True Mean (μ)",
    y = "Average Estimate",
    color = "Type"
  ) +
  scale_color_manual(values = c("avg_estimate" = "blue", "avg_estimate_rejected" = "red"),
                     labels = c("All Simulations", "Rejected Null Only")) +
  theme_minimal()
```
The sample average of μ^ across tests for which the null is rejected is not approximately equal to the true value of μ, particularly for smaller true values of μ. The plot shows the red line (Rejceted Null Only) lies above the blue line (All Simulations) for lower μ, suggesting an upward bias in the average estimate among rejected tests.

## Problem 3

```{r}
# create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides 
homicides <- read_csv("data/homicide-data.csv") |> 
  mutate(
    city_state = paste(city, state, sep = ", "),
    unsolved = disposition %in% c("Closed without arrest", "Open/No arrest")
  )

city_summary <- homicides |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(unsolved)
  )

head(city_summary)
```

```{r}
baltimore <- city_summary |> 
  filter(city_state == "Baltimore, MD")

# use the prop.test function to estimate the proportion of homicides that are unsolved
balt_prop_test <- prop.test(
  x = baltimore$unsolved_homicides,
  n = baltimore$total_homicides
)

balt_tidy <- tidy(balt_prop_test) |> 
  select(estimate, conf.low, conf.high)

balt_tidy
```

```{r}
# run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

city_props <- city_summary |> 
  mutate(
    test_results = map2(
      unsolved_homicides, 
      total_homicides, 
      ~ broom::tidy(prop.test(.x, .y))
    )
  ) |> 
  unnest(test_results) |> 
  select(city_state, estimate, conf.low, conf.high)

head(city_props)
```

```{r}
# Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

city_props |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion (with 95% CI)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
